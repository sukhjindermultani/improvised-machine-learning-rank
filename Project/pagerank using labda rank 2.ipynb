{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/sukhjinder/anaconda/lib/python2.7/site-packages/pycuda/_driver.so: undefined symbol: _ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEED1Ev",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e0fd04d50b7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoinit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSourceModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sukhjinder/anaconda/lib/python2.7/site-packages/pycuda/driver.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_driver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"_v2\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/sukhjinder/anaconda/lib/python2.7/site-packages/pycuda/_driver.so: undefined symbol: _ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEED1Ev"
     ]
    }
   ],
   "source": [
    "#@Author:Sukhjinder Singh\n",
    "# Implement ranking based on train models using lambdamart\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "\n",
    "# Return the list of the dcg by browsing the list of documents \n",
    "def dcg(scores):\n",
    "    return np.sum([(np.power(2, scores[i]) - 1) / np.log2(i + 2) for i in range(len(scores))]) \n",
    "\n",
    "#truncating, that is, taking only the first k documents\n",
    "def dcg_l(scores, l):\n",
    "    return np.sum([(np.power(2, scores[i]) - 1) / np.log2(i + 2) for i in range(len(scores[:l]))])\n",
    "\n",
    "# Return the list of the dcg by browsing the list of documents in the descending order of the scores \n",
    "# In other words, the documents are well classified\n",
    "def ideal_dcg(scores):\n",
    "    scores = [score for score in sorted(scores)[::-1]]\n",
    "    return dcg(scores)\n",
    "\n",
    "# Return the list of the dcg by browsing the list of documents in the descending order of the scores\n",
    "# (and truncating, that is, taking only the first k documents)\n",
    "def ideal_dcg_l(scores, l):\n",
    "    scores = [score for score in sorted(scores)[::-1]]\n",
    "    return dcg_l(scores, l)\n",
    "\n",
    "# Returns the dcg of two documents \n",
    "def single_dcg(scores, i, j):\n",
    "    return (np.power(2, scores[i]) - 1) / np.log2(j + 2)\n",
    "\n",
    "\n",
    "def group_queries(training_data, qid_index):\n",
    "    # We create a dictionary whose keys are the queries and the values the lists of places of the documents in the list\n",
    "    # documents used in the train database (list of lists containing the query the score and the features associated with the documents)\n",
    "    query_indexes = {}\n",
    "    index = 0\n",
    "    for record in training_data:\n",
    "        query_indexes.setdefault(record[qid_index], [])\n",
    "        query_indexes[record[qid_index]].append(index)\n",
    "        index += 1\n",
    "    return query_indexes\n",
    " \n",
    "# At the input of the function, we have a list of score lists according to the request\n",
    "def get_pairs(scores):\n",
    "    # We define a list\n",
    "    query_pair = []\n",
    "    # Here we go through the lists in the list\n",
    "    for query_scores in scores:\n",
    "        # We sort the scores in descending order (highest scores in premiere)+\n",
    "        temp = sorted(query_scores, reverse=True)\n",
    "        pairs = []\n",
    "        for i in range(len(temp)):\n",
    "            for j in range(len(temp)):\n",
    "                if temp[i] > temp[j]:\n",
    "                    pairs.append((i,j))\n",
    "        # We add to the final list \n",
    "        query_pair.append(pairs)\n",
    "    return query_pair\n",
    "\n",
    "\n",
    "\n",
    "class LambdaMART:\n",
    "\n",
    "    #We fix 5 trees and a learning rate of 0.1 .. we can test other learning rate after !!\n",
    "    def __init__(self, training_data=None, number_of_trees=5, learning_rate=0.1):\n",
    "        self.training_data = training_data\n",
    "        self.number_of_trees = number_of_trees\n",
    "        self.learning_rate = learning_rate\n",
    "        self.trees = []\n",
    "    \n",
    "    #The function fit allows to fitter the lambdas tree\n",
    "    def fit(self):\n",
    "        # We define as many predicted scores as lines in the training set\n",
    "        predicted_scores = np.zeros(len(self.training_data))\n",
    "        # We define our dictionary whose keys are the requests and the values the places of the documents\n",
    "        # in the list of documents (the 1 because the second value of the list for each document has the second place the request)\n",
    "        query_indexes = group_queries(self.training_data, 1)\n",
    "        # We retrieve the list of queue\n",
    "        query_keys = query_indexes.keys()\n",
    "        # We obtain here a list of lists of scores, by request\n",
    "        true_scores = [self.training_data[query_indexes[query], 0] for query in query_keys]\n",
    "        # We obtain here the pairs of documents for each list of scores, so for each request\n",
    "        pairs = get_pairs(true_scores)\n",
    "        # Here we obtain the set of feature vectors for documents\n",
    "        tree_data = pd.DataFrame(self.training_data[:, 2:7])\n",
    "        # We obtain here all the scores for the documents (the labels)\n",
    "        labels = self.training_data[:, 0]\n",
    "        # The list of dcg is calculated for the lists of scores ranked in descending order (ideal ranking)\n",
    "        # We get a list of lists again\n",
    "        idcg = [ideal_dcg(scores) for scores in true_scores]\n",
    "        # We go through the number of trees \n",
    "        for k in range(self.number_of_trees):\n",
    "            \n",
    "            # We create as many lambdas as we have lines in our training set\n",
    "            lambdaFinal = np.ones(len(predicted_scores))\n",
    "            w = np.zeros(len(predicted_scores))\n",
    "            pred_scores = [predicted_scores[query_indexes[query]] for query in query_keys]\n",
    "            \n",
    "            \n",
    "            # SEND DATA TO THE GPU\n",
    "            \n",
    "            # We allocate the right size in the memory of the GPU\n",
    "            lambda_gpu = cuda.mem_alloc(lambdaFinal.nbytes)\n",
    "            # Puis on prépare l'envoi de la variable vers le GPU ! (bien vérifier qu'elle est de type array, sinon la convertir)\n",
    "            cuda.memcpy_htod(lambda_gpu, lambdaFinal)\n",
    "            # Et ainsi de suite pour toutes les variables\n",
    "        \n",
    "            pred_scores=np.asarray(pred_scores)\n",
    "            pred_scores_gpu=cuda.mem_alloc(pred_scores.nbytes)\n",
    "            cuda.memcpy_htod(pred_scores_gpu, pred_scores)\n",
    "            \n",
    "            tuple1=[([i[j][0] for j in range(len(i))])  for i in pairs]\n",
    "            tuple2=[([i[j][1]  for j in range(len(i))])  for i in pairs]\n",
    "        \n",
    "            true_scores=np.asarray(true_scores)\n",
    "            true_scores_gpu = cuda.mem_alloc(true_scores.nbytes)\n",
    "            cuda.memcpy_htod(true_scores_gpu, true_scores)\n",
    "\n",
    "            predicted_scores_gpu = cuda.mem_alloc(predicted_scores.nbytes)\n",
    "            cuda.memcpy_htod(predicted_scores_gpu, predicted_scores)\n",
    "\n",
    "            tuple11=np.array(tuple1)\n",
    "            tuple11_gpu = cuda.mem_alloc(tuple11.nbytes)\n",
    "            cuda.memcpy_htod(tuple11_gpu, tuple11)\n",
    "            tuple2=np.asarray(tuple2)\n",
    "            tuple2_gpu = cuda.mem_alloc(tuple2.nbytes)\n",
    "            cuda.memcpy_htod(tuple2_gpu, tuple2)\n",
    "\n",
    "            idcg=np.asarray(idcg)\n",
    "\n",
    "            idcg_gpu = cuda.mem_alloc(idcg.nbytes)\n",
    "            cuda.memcpy_htod(idcg_gpu, idcg)\n",
    "\n",
    "            \n",
    "            query_keys2=[[int(key)] for key in list(query_keys)]\n",
    "            query_keys2=np.array(query_keys2, )\n",
    "           \n",
    "            \n",
    "            query_keys_gpu = cuda.mem_alloc(query_keys2.nbytes)\n",
    "            cuda.memcpy_htod(query_keys_gpu, query_keys2)\n",
    "\n",
    "            \n",
    "            keys=list(query_indexes.keys())\n",
    "            lengthValues=[len(query_indexes[key]) for key in keys]\n",
    "            maxLengthValues=max(lengthValues)\n",
    "            \n",
    "            tab=[]\n",
    "\n",
    "            for i in range(len(keys)):\n",
    "                tabint=[]\n",
    "                tabint.append(int(keys[i]))\n",
    "                tabint.append(lengthValues[i])\n",
    "               \n",
    "                for k in range(2,lengthValues[i]+2):\n",
    "                    tabint.append(query_indexes[keys[i]][k-2])\n",
    "                for l in range(lengthValues[i]+2,maxLengthValues):\n",
    "                    tabint.append(0)\n",
    "                tab.append(tabint)\n",
    "            \n",
    "            tab=np.asarray(tab)\n",
    "            \n",
    "            \n",
    "            tab_gpu = cuda.mem_alloc(tab.nbytes)\n",
    "            cuda.memcpy_htod(tab_gpu, tab)\n",
    "            \n",
    "            nb=len(keys)\n",
    "            nbKeys=[nb]\n",
    "            nbKeys=np.asarray(nbKeys)\n",
    "            nbKeys_gpu = cuda.mem_alloc(nbKeys.nbytes)\n",
    "            cuda.memcpy_htod(nbKeys_gpu, nbKeys)\n",
    "            \n",
    "            maxLengthValues = np.int_(maxLengthValues)\n",
    "            maxLengthValues_gpu = cuda.mem_alloc(maxLengthValues.nbytes)\n",
    "            cuda.memcpy_htod(maxLengthValues_gpu, maxLengthValues)\n",
    "        \n",
    "            \n",
    "            \n",
    "            # END OF SENDING DATA TO THE GPU\n",
    "          \n",
    "            \n",
    "            # START OF WRITING C FUNCTIONS (which will run on the GPU). This code (especially \n",
    "            # the function compute_lambda), does the same thing as the code explained in the part above, in python,\n",
    "            # but this time in C (with the object and syntax changes that implies)\n",
    "\n",
    "            mod = SourceModule(\"\"\"\n",
    "        \n",
    "            #include <stdio.h>\n",
    "            #include <math.h>\n",
    "            \n",
    "            __device__ int comp(const void * elem1, const void * elem2) {\n",
    "                int f = *((int*)elem1);\n",
    "                int s = *((int*)elem2);\n",
    "                if (f > s) return  1;\n",
    "                if (f < s) return -1;\n",
    "                return 0;\n",
    "            }\n",
    "\n",
    "            __device__ void swap(int *xp, int *yp)\n",
    "            {\n",
    "                int temp = *xp;\n",
    "                *xp = *yp;\n",
    "                *yp = temp;\n",
    "            }\n",
    "\n",
    "\n",
    "            __device__ void bubbleSort(int arr[], int n)\n",
    "            {\n",
    "               int i, j;\n",
    "               for (i = 0; i < n-1; i++)      \n",
    "\n",
    "                   // Last i elements are already in place   \n",
    "                   for (j = 0; j < n-i-1; j++) \n",
    "                       if (arr[j] > arr[j+1])\n",
    "                          swap(&arr[j], &arr[j+1]);\n",
    "            }\n",
    "            __device__ void swapDouble(double *xp, double *yp)\n",
    "            {\n",
    "                double temp = *xp;\n",
    "                *xp = *yp;\n",
    "                *yp = temp;\n",
    "            }\n",
    "\n",
    "\n",
    "            __device__ void bubbleSortDouble(double arr[], int n)\n",
    "            {\n",
    "               int i, j;\n",
    "               for (i = 0; i < n-1; i++)      \n",
    "\n",
    "                   // Last i elements are already in place   \n",
    "                   for (j = 0; j < n-i-1; j++) \n",
    "                       if (arr[j] > arr[j+1])\n",
    "                          swapDouble(&arr[j], &arr[j+1]);\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "                 __device__ int compute_lambda(int *maxLengthValues, int *true_scores, double *predited_scores, int *tuple1, int *tuple2, double *idcg, int *query_key, int tab[][5], int *nbKeys, double *lambda){  \n",
    "\n",
    "\n",
    "\n",
    "               int i = 0;\n",
    "               int j = 0;\n",
    "               int q = 0;\n",
    "               int val=0;\n",
    "\n",
    "\n",
    "\n",
    "                double predited_scores_copy[sizeof(predited_scores)/sizeof(predited_scores[0])];\n",
    "                for (i = 0; i < sizeof(predited_scores)/sizeof(predited_scores[0]); i++) {\n",
    "                     predited_scores_copy[i] = predited_scores[i];   \n",
    "                 }\n",
    "\n",
    "\n",
    "                bubbleSortDouble(predited_scores, sizeof(predited_scores)/sizeof(predited_scores[0]));\n",
    "\n",
    "\n",
    "\n",
    "                int argsort[sizeof(predited_scores)/sizeof(predited_scores[0])] ;\n",
    "                 for (i = 0; i < sizeof(predited_scores)/sizeof(predited_scores[0]); i++) {\n",
    "                     for (j= 0; j < sizeof(predited_scores)/sizeof(predited_scores[0]); j++) {\n",
    "                        val=0;\n",
    "                         if(predited_scores_copy[j] == predited_scores[i]) {\n",
    "                         for (q= 0; q < sizeof(argsort)/sizeof(argsort[0]); q++){\n",
    "                         if(argsort[q] == j) val=1;\n",
    "\n",
    "                          }\n",
    "                         if (val==0) argsort[i] = j;\n",
    "                          }\n",
    "                          else  {\n",
    "\n",
    "                          }\n",
    "\n",
    "                 }\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "                int u = sizeof(argsort)/sizeof(argsort[0]) - 1;\n",
    "                int argsort2[sizeof(predited_scores)/sizeof(predited_scores[0])];\n",
    "\n",
    "                for (i = 0 ; i < u+1 ; i++) {\n",
    "                    argsort2[i] = argsort[u];\n",
    "                    u--;  \n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "                int argsort_copy[sizeof(argsort2)/sizeof(argsort2[0])];\n",
    "                for (i = 0; i < sizeof(argsort2)/sizeof(argsort2[0]); i++) {\n",
    "                     argsort_copy[i] = argsort2[i];   \n",
    "                 }\n",
    "\n",
    "\n",
    "                bubbleSort(argsort2, sizeof(argsort2)/sizeof(argsort2[0]));\n",
    "\n",
    "\n",
    "               int val2=0;\n",
    "\n",
    "                int rev_argsort[sizeof(argsort2)/sizeof(argsort2[0])];\n",
    "                 for (i = 0; i < sizeof(argsort2)/sizeof(argsort2[0]); i++) {\n",
    "                 val2=0;\n",
    "                     for (j= 0; j < sizeof(argsort2)/sizeof(argsort2[0]); j++) {\n",
    "\n",
    "                      if(argsort_copy[j] == argsort2[i]) {\n",
    "                         for (q= 0; q < sizeof(rev_argsort)/sizeof(rev_argsort[0]); q++){\n",
    "                         if(rev_argsort[q] == j) val2=1;\n",
    "                          }\n",
    "                          if (val2==0) rev_argsort[i] = j;\n",
    "                          }\n",
    "\n",
    "                }\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "                int true_scores2[sizeof(predited_scores)/sizeof(predited_scores[0])];\n",
    "                for (i = 0; i < sizeof(argsort2)/sizeof(argsort2[0]); i++) {\n",
    "                     true_scores2[i] = true_scores[argsort2[i]];\n",
    "                 }\n",
    "\n",
    "\n",
    "                int predited_scores2[sizeof(predited_scores)/sizeof(predited_scores[0])];\n",
    "                for (i = 0; i < sizeof(argsort2)/sizeof(argsort2[0]); i++) {\n",
    "                     predited_scores2[i] = predited_scores[argsort2[i]];\n",
    "                 }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "               double tableau[sizeof(argsort2)/sizeof(argsort2[0])][sizeof(argsort2)/sizeof(argsort2[0])] ={0};\n",
    "\n",
    "                for (i = 0; i < sizeof(tuple1)/sizeof(tuple1[0]); i++) {\n",
    "\n",
    "                tableau[tuple1[i]][tuple1[i]] = (double)( pow((double) 2,(double) true_scores2[tuple1[i]]) - 1) / log2((double) tuple1[i] + 2);\n",
    "                tableau[tuple1[i]][tuple2[i]] = (double)( pow((double) 2,(double) true_scores2[tuple1[i]]) - 1) / log2((double) tuple2[i] + 2);\n",
    "                tableau[tuple2[i]][tuple2[i]] = (double)( pow((double) 2,(double) true_scores2[tuple2[i]]) - 1) / log2((double) tuple2[i] + 2);\n",
    "                tableau[tuple2[i]][tuple1[i]] = (double)( pow((double) 2,(double) true_scores2[tuple2[i]]) - 1) / log2((double) tuple1[i] + 2);\n",
    "\n",
    "              }\n",
    "\n",
    "                double z_ndcg = 0;\n",
    "                double rho = 0;\n",
    "                double rho_complement = 0;\n",
    "                double lambda_val = 0;\n",
    "                double lambdas[sizeof(true_scores2)/sizeof(true_scores2[0])]={0};\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                for (i = 0; i < sizeof(tuple1)/sizeof(tuple1[0]); i++) {\n",
    "                        double insideexp=predited_scores2[tuple1[i]] - predited_scores2[tuple2[i]];\n",
    "                        z_ndcg = (double) abs(tableau[tuple1[i]][tuple2[i]] - tableau[tuple1[i]][tuple1[i]] + tableau[tuple2[i]][tuple1[i]] - tableau[tuple2[i]][tuple2[i]]) / idcg[0];\n",
    "                        rho = (double) 1/(double) (1 + exp2(insideexp));\n",
    "                        rho_complement = 1.0 - rho;\n",
    "                        lambda_val = (double) z_ndcg * rho;\n",
    "                        lambdas[tuple1[i]] += lambda_val;\n",
    "                        lambdas[tuple2[i]] -= lambda_val;\n",
    "\n",
    "\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "                for (i = 0; i < sizeof(lambdas)/sizeof(lambdas[0]); i++) {\n",
    "                     lambdas[i] = lambdas[rev_argsort[i]];\n",
    "                 }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                int count=0;\n",
    "                int pair=0;\n",
    "\n",
    "                for (i = 0; i < nbKeys[0]*5*2+6 ; i++) {\n",
    "\n",
    "                 if (tab[0][i] == query_key[0] ) {\n",
    "                    for (j = i+4; j < i+3*2+4; j++) {\n",
    "                        if (pair==0) {\n",
    "                        lambda[tab[0][j]] = lambdas[count];\n",
    "                        count+=1;\n",
    "                        pair=1;\n",
    "                        }\n",
    "                        else {\n",
    "                        pair=0;\n",
    "                        }\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "                return 0;\n",
    "              } \n",
    "                  __global__ void fill_lambdas(int *maxLengthValues, double *lambda, int *true_scores, double *predited_scores, int *tuple1,int *tuple2,double *idcg,int *query_keys, int tab[][5], int *nbKeys)\n",
    "                  {\n",
    "                     compute_lambda(maxLengthValues, &true_scores[threadIdx.x], &predited_scores[threadIdx.x], &tuple1[threadIdx.x], &tuple2[threadIdx.x], &idcg[threadIdx.x], &query_keys[threadIdx.x], tab, nbKeys, lambda);      \n",
    "                  }         \n",
    "\n",
    "            \"\"\")\n",
    "            \n",
    "            \n",
    "            # We will call the function fill_lambdas (which itself calls compute_lambda cf explanations above) by passing arguing the variables prepared upstream\n",
    "            fill_lambdas_c = mod.get_function(\"fill_lambdas\")\n",
    "            fill_lambdas_c(maxLengthValues_gpu, lambda_gpu, true_scores_gpu, pred_scores_gpu, tuple11_gpu, tuple2_gpu, idcg_gpu, query_keys_gpu, tab_gpu, nbKeys_gpu, block=(4,1,1))\n",
    "            \n",
    "            \n",
    "            lambdas = np.ones_like(lambdaFinal)\n",
    "            # we recover the lambdas that interests us\n",
    "            cuda.memcpy_dtoh(lambdas, lambda_gpu)\n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "            # Implementation of the scikit-learn tree\n",
    "            tree = DecisionTreeRegressor(max_depth=50)\n",
    "            # We made the lambdas tree\n",
    "            tree.fit(self.training_data[:,2:], lambdas)\n",
    "            # We add the tree to our list of trees\n",
    "            self.trees.append(tree)\n",
    "            # We predict thanks to our tree and our features (the predict function is below)\n",
    "            # Calculate the prediction for each document thanks to our previous trees and the new\n",
    "                \n",
    "            prediction = tree.predict(self.training_data[:,2:])\n",
    "            # On update our predictions using our recent prediction and learning_rate\n",
    "            predicted_scores += prediction * self.learning_rate\n",
    "\n",
    "    \n",
    "    def predict(self, data):\n",
    "        data = np.array(data)\n",
    "        query_indexes = group_queries(data, 0)\n",
    "        predicted_scores = np.zeros(len(data))\n",
    "        for query in query_indexes:\n",
    "            results = np.zeros(len(query_indexes[query]))\n",
    "            for tree in self.trees:\n",
    "                results += self.learning_rate * tree.predict(data[query_indexes[query], 1:])\n",
    "            predicted_scores[query_indexes[query]] = results\n",
    "        return predicted_scores\n",
    "\n",
    "    #Validate function that predicts on the test base according to all the trees we have built, which also calculates the NDCG average\n",
    "    def validate(self, data, k):\n",
    "        data = np.array(data)\n",
    "        query_indexes = group_queries(data, 1)\n",
    "        average_ndcg = []\n",
    "        predicted_scores = np.zeros(len(data))\n",
    "        for query in query_indexes:\n",
    "            results = np.zeros(len(query_indexes[query]))\n",
    "            for tree in self.trees:\n",
    "                results += self.learning_rate * tree.predict(data[query_indexes[query], 2:])\n",
    "            predicted_sorted_indexes = np.argsort(results)[::-1]\n",
    "            t_results = data[query_indexes[query], 0]\n",
    "            t_results = t_results[predicted_sorted_indexes]\n",
    "            predicted_scores[query_indexes[query]] = results\n",
    "            dcg_val = dcg_l(t_results, k)\n",
    "            idcg_val = ideal_dcg_l(t_results, k)\n",
    "            ndcg_val = (dcg_val / idcg_val)\n",
    "            average_ndcg.append(ndcg_val)\n",
    "        average_ndcg = np.nanmean(average_ndcg)\n",
    "        return average_ndcg, predicted_scores\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'LambdaMART' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fcbe94f5f308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-fcbe94f5f308>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# We build the 100 trees on the test base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambdaMART\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# We truncate on the first 10 docs for the calculations of the DCG average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'LambdaMART' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    total_ndcg = 0.0\n",
    "    df=pd.read_csv('train2.csv')\n",
    "    values=[[df.loc[(df.index == j),][str(u)][j] for u in list(range(1,49))] for j in range(len(df.index))][0:18]\n",
    "    training_data = np.asarray(values)\n",
    "    df2=pd.read_csv('test2.csv')\n",
    "    values2=[[df2.loc[(df2.index == j),][str(u)][j] for u in list(range(1,49))] for j in range(len(df2.index))][0:18]\n",
    "    test_data = np.asarray(values2)\n",
    "    # We build the 100 trees on the test base\n",
    "    model = LambdaMART(training_data, 100, 0.001)\n",
    "    model.fit()\n",
    "    # We truncate on the first 10 docs for the calculations of the DCG average\n",
    "    # Predicted scores are calculated on the test basis\n",
    "    average_ndcg, predicted_scores = model.validate(test_data, 10) \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
